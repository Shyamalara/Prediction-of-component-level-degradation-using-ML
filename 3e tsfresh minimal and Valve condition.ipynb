{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.fft import fft, ifft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn.metrics as metrics \n",
    "\n",
    "from random import randint\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh import select_features\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh import extract_relevant_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh import extract_features, extract_relevant_features, select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh.feature_extraction import ComprehensiveFCParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,f1_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing the data\n",
    "## pressure sensors are imported as PS. There are around 6 pressure sensors. They are named as ps1, ps2, ps3, ps4, ps5, ps6. \n",
    "\n",
    "df_ps1 = pd.read_csv('PS1.txt', delimiter = '\\t', header = None)\n",
    "df_ps2 = pd.read_csv('PS2.txt', delimiter = '\\t', header = None)\n",
    "df_ps3 = pd.read_csv('PS3.txt', delimiter = '\\t', header = None)\n",
    "df_ps4 = pd.read_csv('PS4.txt', delimiter = '\\t', header = None)\n",
    "df_ps5 = pd.read_csv('PS5.txt', delimiter = '\\t', header = None)\n",
    "df_ps6 = pd.read_csv('PS6.txt', delimiter = '\\t', header = None)\n",
    "\n",
    "## cooling efficiency and cooling power are imported as ce and cp respectively. \n",
    "\n",
    "df_ce = pd.read_csv('CE.txt',delimiter = '\\t', header = None)\n",
    "df_cp = pd.read_csv('CP.txt', delimiter = '\\t', header = None)\n",
    "\n",
    "\n",
    "# temperature sensors are imported as ts. There are around 4 pressure sensors. They are named as ts1, ts2, ts3, ts4.\n",
    "\n",
    "df_ts1 = pd.read_csv('TS1.txt', delimiter = '\\t', header = None)\n",
    "df_ts2 = pd.read_csv('TS2.txt', delimiter = '\\t', header = None)\n",
    "df_ts3 = pd.read_csv('TS3.txt', delimiter = '\\t', header = None)\n",
    "df_ts4 = pd.read_csv('TS4.txt', delimiter = '\\t', header = None)\n",
    "\n",
    "\n",
    "# flow sensors are imported as fs. There are around 2 pressure sensors. They are named as fs1, fs2.\n",
    "\n",
    "df_fs1 = pd.read_csv('FS1.txt', delimiter = '\\t', header = None)\n",
    "df_fs2 = pd.read_csv('FS2.txt', delimiter = '\\t', header = None)\n",
    "\n",
    "\n",
    "# motor power sensors is imported as eps. \n",
    "# vibration sensors is imported as vs\n",
    "# efficiency power is imported as se\n",
    "\n",
    "df_eps1 = pd.read_csv('EPS1.txt', delimiter = '\\t', header = None)\n",
    "df_se = pd.read_csv('SE.txt', delimiter = '\\t', header = None)\n",
    "df_vs1 = pd.read_csv('VS1.txt', delimiter = '\\t', header = None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function for defining variables like ps1_1, ps1_2 for 17 sensors with different sampling rates\n",
    "\n",
    "def col(n, var):\n",
    "    l = []\n",
    "    for i in range(1,n):\n",
    "        temp = str(var) + '_' + '%d' %i\n",
    "        l.append(temp)\n",
    "    return l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "df_ps1.columns = col(6001,'ps1')\n",
    "df_ps2.columns = col(6001,'ps2')\n",
    "df_ps3.columns = col(6001,'ps3')\n",
    "df_ps4.columns = col(6001,'ps4')\n",
    "df_ps5.columns = col(6001,'ps5')\n",
    "df_ps6.columns = col(6001,'ps6')\n",
    "\n",
    "\n",
    "df_ts1.columns = col(61,'ts1')\n",
    "df_ts2.columns = col(61,'ts2')\n",
    "df_ts3.columns = col(61,'ts3')\n",
    "df_ts4.columns = col(61,'ts4')\n",
    "\n",
    "\n",
    "df_eps1.columns = col(6001,'eps1')\n",
    "\n",
    "df_fs1.columns = col(601,'fs1')\n",
    "df_fs2.columns = col(601,'fs2')\n",
    "\n",
    "df_vs1.columns = col(61,'vs1')\n",
    "\n",
    "df_ce.columns = col(61,'ce')\n",
    "\n",
    "df_cp.columns = col(61,'cp')\n",
    "\n",
    "df_se.columns = col(61,'se')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ps = pd.concat([df_ps1, df_ps2, df_ps3, df_ps4, df_ps5, df_ps6], axis = 1)\n",
    "df_ts = pd.concat([df_ts1, df_ts2, df_ts3, df_ts4], axis = 1)\n",
    "df_fs = pd.concat([df_fs1, df_fs2], axis = 1)\n",
    "df_vir = pd.concat([df_cp, df_ce, df_eps1, df_se, df_vs1], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ps1_1</th>\n",
       "      <th>ps1_2</th>\n",
       "      <th>ps1_3</th>\n",
       "      <th>ps1_4</th>\n",
       "      <th>ps1_5</th>\n",
       "      <th>ps1_6</th>\n",
       "      <th>ps1_7</th>\n",
       "      <th>ps1_8</th>\n",
       "      <th>ps1_9</th>\n",
       "      <th>ps1_10</th>\n",
       "      <th>...</th>\n",
       "      <th>vs1_51</th>\n",
       "      <th>vs1_52</th>\n",
       "      <th>vs1_53</th>\n",
       "      <th>vs1_54</th>\n",
       "      <th>vs1_55</th>\n",
       "      <th>vs1_56</th>\n",
       "      <th>vs1_57</th>\n",
       "      <th>vs1_58</th>\n",
       "      <th>vs1_59</th>\n",
       "      <th>vs1_60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>151.47</td>\n",
       "      <td>151.45</td>\n",
       "      <td>151.52</td>\n",
       "      <td>151.27</td>\n",
       "      <td>150.80</td>\n",
       "      <td>150.69</td>\n",
       "      <td>153.89</td>\n",
       "      <td>154.67</td>\n",
       "      <td>152.88</td>\n",
       "      <td>153.82</td>\n",
       "      <td>...</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151.11</td>\n",
       "      <td>151.12</td>\n",
       "      <td>151.16</td>\n",
       "      <td>150.92</td>\n",
       "      <td>150.70</td>\n",
       "      <td>150.62</td>\n",
       "      <td>152.40</td>\n",
       "      <td>153.21</td>\n",
       "      <td>152.81</td>\n",
       "      <td>153.53</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150.81</td>\n",
       "      <td>150.79</td>\n",
       "      <td>150.84</td>\n",
       "      <td>150.65</td>\n",
       "      <td>150.35</td>\n",
       "      <td>150.23</td>\n",
       "      <td>152.03</td>\n",
       "      <td>152.81</td>\n",
       "      <td>152.44</td>\n",
       "      <td>153.27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150.48</td>\n",
       "      <td>150.47</td>\n",
       "      <td>150.52</td>\n",
       "      <td>150.31</td>\n",
       "      <td>150.04</td>\n",
       "      <td>149.98</td>\n",
       "      <td>151.63</td>\n",
       "      <td>152.48</td>\n",
       "      <td>152.24</td>\n",
       "      <td>152.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.549</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150.41</td>\n",
       "      <td>150.35</td>\n",
       "      <td>150.24</td>\n",
       "      <td>150.12</td>\n",
       "      <td>149.87</td>\n",
       "      <td>149.71</td>\n",
       "      <td>151.64</td>\n",
       "      <td>152.37</td>\n",
       "      <td>151.78</td>\n",
       "      <td>152.68</td>\n",
       "      <td>...</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.549</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43680 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ps1_1   ps1_2   ps1_3   ps1_4   ps1_5   ps1_6   ps1_7   ps1_8   ps1_9  \\\n",
       "0  151.47  151.45  151.52  151.27  150.80  150.69  153.89  154.67  152.88   \n",
       "1  151.11  151.12  151.16  150.92  150.70  150.62  152.40  153.21  152.81   \n",
       "2  150.81  150.79  150.84  150.65  150.35  150.23  152.03  152.81  152.44   \n",
       "3  150.48  150.47  150.52  150.31  150.04  149.98  151.63  152.48  152.24   \n",
       "4  150.41  150.35  150.24  150.12  149.87  149.71  151.64  152.37  151.78   \n",
       "\n",
       "   ps1_10  ...  vs1_51  vs1_52  vs1_53  vs1_54  vs1_55  vs1_56  vs1_57  \\\n",
       "0  153.82  ...   0.554   0.552   0.545   0.553   0.553   0.539   0.544   \n",
       "1  153.53  ...   0.555   0.547   0.548   0.544   0.536   0.542   0.540   \n",
       "2  153.27  ...   0.543   0.544   0.543   0.554   0.544   0.544   0.545   \n",
       "3  152.94  ...   0.549   0.538   0.553   0.543   0.553   0.555   0.544   \n",
       "4  152.68  ...   0.546   0.546   0.544   0.552   0.539   0.540   0.549   \n",
       "\n",
       "   vs1_58  vs1_59  vs1_60  \n",
       "0   0.545   0.535   0.543  \n",
       "1   0.533   0.531   0.534  \n",
       "2   0.544   0.530   0.534  \n",
       "3   0.543   0.543   0.542  \n",
       "4   0.542   0.533   0.537  \n",
       "\n",
       "[5 rows x 43680 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_ps, df_ts, df_fs, df_vir], axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = pd.read_csv('profile.txt', delimiter = '\\t', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.columns = [\"Cooler Condition\",\"Valve Condition\",\"Internal Pump Leakage\",\"Hydraulic Accumulator\",\"Stable Flag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_valve = profile['Valve Condition']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Features using tsfresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh import select_features\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh import extract_relevant_features\n",
    "\n",
    "from tsfresh import extract_features, extract_relevant_features, select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh.feature_extraction import ComprehensiveFCParameters\n",
    "from tsfresh.feature_extraction import EfficientFCParameters, MinimalFCParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsfreshextract(data):\n",
    "    data[\"id\"] = data.index\n",
    "    data = data.melt(id_vars=\"id\", var_name=\"time\").sort_values([\"id\", \"time\"]).reset_index(drop=True)\n",
    "    data['T'] = data.time.str.extract('(\\d+)')\n",
    "    data['T'].astype(int)\n",
    "    \n",
    "#     y = profile['Stable Flag']\n",
    "#     y = pd.DataFrame(y)\n",
    "#     y = y.reset_index()\n",
    "#     y = y.rename(columns = {'index':'id'})\n",
    "    \n",
    "#     new = pd.merge(left = df, right = y, how = 'inner', on = ['id'])\n",
    "    \n",
    "#     y = new.pop('Stable Flag')\n",
    "    \n",
    "    data = data.drop(['time'], axis = 1)\n",
    "    \n",
    "    X = extract_features(data, column_id=\"id\", column_sort=\"T\", default_fc_parameters = MinimalFCParameters(), \n",
    "                         n_jobs = 1, impute_function=impute)\n",
    "   \n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 5/5 [00:10<00:00,  2.13s/it]\n"
     ]
    }
   ],
   "source": [
    "X_ts1 = tsfreshextract(df_ts1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 5/5 [00:06<00:00,  1.33s/it]\n"
     ]
    }
   ],
   "source": [
    "X_ts2 = tsfreshextract(df_ts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 5/5 [00:06<00:00,  1.24s/it]\n"
     ]
    }
   ],
   "source": [
    "X_ts3 = tsfreshextract(df_ts3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 5/5 [00:05<00:00,  1.17s/it]\n"
     ]
    }
   ],
   "source": [
    "X_ts4 = tsfreshextract(df_ts4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 5/5 [00:06<00:00,  1.28s/it]\n"
     ]
    }
   ],
   "source": [
    "X_fs1 = tsfreshextract(df_fs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 5/5 [00:06<00:00,  1.21s/it]\n"
     ]
    }
   ],
   "source": [
    "X_fs2 = tsfreshextract(df_fs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 5/5 [00:05<00:00,  1.18s/it]\n"
     ]
    }
   ],
   "source": [
    "X_ce = tsfreshextract(df_ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 5/5 [00:05<00:00,  1.12s/it]\n"
     ]
    }
   ],
   "source": [
    "X_cp = tsfreshextract(df_cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 5/5 [00:05<00:00,  1.14s/it]\n"
     ]
    }
   ],
   "source": [
    "X_se = tsfreshextract(df_se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 5/5 [00:05<00:00,  1.10s/it]\n"
     ]
    }
   ],
   "source": [
    "X_vs = tsfreshextract(df_vs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 101. MiB for an array with shape (13230000,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-73cb2fbbf1a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_eps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtsfreshextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_eps1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-32ebb22da797>\u001b[0m in \u001b[0;36mtsfreshextract\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtsfreshextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmelt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid_vars\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"time\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"time\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'T'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'(\\d+)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'T'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36msort_values\u001b[1;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index)\u001b[0m\n\u001b[0;32m   4919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4920\u001b[0m             \u001b[0mkeys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4921\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlexsort_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_position\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_position\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4922\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_platform_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4923\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\sorting.py\u001b[0m in \u001b[0;36mlexsort_indexer\u001b[1;34m(keys, orders, na_position)\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mindexer_from_factorized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\sorting.py\u001b[0m in \u001b[0;36mindexer_from_factorized\u001b[1;34m(labels, shape, compress)\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[0mngroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m         \u001b[0mids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompress_group_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m         \u001b[0mngroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\sorting.py\u001b[0m in \u001b[0;36mcompress_group_index\u001b[1;34m(group_index, sort)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msort\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs_group_ids\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m         \u001b[0mobs_group_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomp_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_reorder_by_uniques\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs_group_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomp_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcomp_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobs_group_ids\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\sorting.py\u001b[0m in \u001b[0;36m_reorder_by_uniques\u001b[1;34m(uniques, labels)\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;31m# reverse_indexer is where elements came from\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m     \u001b[0mreverse_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m     \u001b[0mreverse_indexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m     \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 101. MiB for an array with shape (13230000,) and data type int64"
     ]
    }
   ],
   "source": [
    "X_eps = tsfreshextract(df_eps1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ps1 = tsfreshextract(df_ps1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ps2 = tsfreshextract(df_ps2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ps3 = tsfreshextract(df_ps3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ps4 = tsfreshextract(df_ps4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ps5 = tsfreshextract(df_ps5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ps6 = tsfreshextract(df_ps6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train -Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_ps1,X_ps2,X_ps3,X_ps4,X_ps5,X_ps6,X_fs1,X_fs2,X_ce,X_cp,X_se,X_eps,X_ts1, X_ts2, X_ts3, X_ts4, X_vs], axis = 1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv('X_extractedfull.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, profile_valve, train_size=0.7, test_size=0.3, random_state=42,stratify = profile_valve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_traindf = pd.DataFrame(y_train)\n",
    "y_testdf = pd.DataFrame(y_test)\n",
    "\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## SMOTE method is used to balance data\n",
    "from imblearn import under_sampling \n",
    "from imblearn import over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smt = SMOTE(random_state=45, k_neighbors=5)\n",
    "X_train, y_train = smt.fit_sample(X_train,y_train)\n",
    "X_train = pd.DataFrame(X_train, columns=X_train.columns)\n",
    "\n",
    "y_train_smt = pd.DataFrame(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_smt['Valve Condition'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler() ## x-mean/std\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = pd.DataFrame(X_train_scaled)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.columns = X.columns \n",
    "X_test_scaled.columns = X.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,f1_score\n",
    "from sklearn.model_selection import cross_validate,GridSearchCV,RandomizedSearchCV\n",
    "\n",
    "from scipy.stats import randint\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(dt_classifier,y_train,X_train,y_test,X_test):\n",
    "    print(\"Train Precision :\", (precision_score(y_train, dt_classifier.predict(X_train)))*100)\n",
    "    print(\"Train Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_train, dt_classifier.predict(X_train)))\n",
    "    print(\"-\"*50)\n",
    "    print(\"Test Precision :\", (precision_score(y_test, dt_classifier.predict(X_test)))*100)\n",
    "    print(\"Test Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, dt_classifier.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM for Cooler condition classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a linear SVM classifier\n",
    "from sklearn.svm import SVC\n",
    "svm_model_linear = SVC(kernel = 'linear', C = 1).fit(X_train_scaled, y_train)\n",
    "svm_predictions = svm_model_linear.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a confusion matrix\n",
    "cm = confusion_matrix(y_test, svm_predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmatrix(model):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    disp = metrics.plot_confusion_matrix(model, X_test_scaled,y_test,ax = ax,\n",
    "                                        display_labels = ['close to total failure','severe lag','small lag','optimal switching behavior'])\n",
    "    return disp.confusion_matrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmatrix(svm_model_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, svm_model_linear.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score_svm = svm_model_linear.fit(X_train_scaled, y_train).decision_function(X_test)\n",
    "y_score_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "def plot_multiclass_roc(y_score, X_test, y_test, n_classes= 3, figsize = (20,6)):\n",
    "\n",
    "    # structures\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    # calculate dummies once\n",
    "    y_test_dummies = pd.get_dummies(y_test, drop_first=False).values\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_dummies[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.plot([0, 1], [0, 1], 'k--')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('Receiver operating characteristic example')\n",
    "    for i in range(n_classes):\n",
    "        ax.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f) for label %i' % (roc_auc[i], i))\n",
    "    ax.legend(loc=\"best\")\n",
    "    ax.grid(alpha=.4)\n",
    "    sns.despine()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiclass_roc(y_score_svm,X_test_scaled, y_test, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building an RF classifier for Cooler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_rf = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)\n",
    "classifier_rf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmatrix(classifier_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score_rf = classifier_rf.fit(X_train_scaled, y_train).predict_proba(X_test_scaled)\n",
    "y_score_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiclass_roc(y_score_rf, X_test_scaled, y_test, n_classes=4, figsize=(20, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, classifier_rf.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN for cooler failure classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a KNN classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 7).fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmatrix(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score_knn = knn.fit(X_train_scaled, y_train).predict_proba(X_test)\n",
    "y_score_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiclass_roc(y_score_knn, X_test_scaled, y_test, n_classes=4, figsize=(20, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, knn.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance in Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "mu, sigma = 0, np.std(X_test_scaled)*0.20\n",
    "noise = np.random.normal(mu, sigma, X_test_scaled.shape)\n",
    "\n",
    "X_testnoise = X_test_scaled + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, classifier_rf.predict(X_testnoise)))\n",
    "\n",
    "y_score_rf_hypernoise = classifier_rf.fit(X_train_scaled, y_train).predict_proba(X_testnoise)\n",
    "y_score_rf_hypernoise\n",
    "\n",
    "plot_multiclass_roc(y_score_rf_hypernoise, X_testnoise, y_test, n_classes=4, figsize=(20, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, knn.predict(X_testnoise)))\n",
    "\n",
    "y_score_knnnoise = knn.fit(X_train_scaled, y_train).predict_proba(X_testnoise)\n",
    "y_score_knnnoise\n",
    "\n",
    "plot_multiclass_roc(y_score_knnnoise, X_testnoise, y_test, n_classes=4, figsize=(20, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, svm_model_linear.predict(X_testnoise)))\n",
    "\n",
    "y_score_svmnoise = svm_model_linear.fit(X_train_scaled, y_train).decision_function(X_testnoise)\n",
    "y_score_svmnoise\n",
    "\n",
    "plot_multiclass_roc(y_score_svmnoise, X_testnoise, y_test, n_classes=4, figsize=(20, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Gradient boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# First we construct our gradient boosting model, \n",
    "# We specify 500 trees to start, each with a maximum \n",
    "# depth of three. We also specify the random_state \n",
    "# hyperparameter to ensure reproduceability.\n",
    "gbtc = GradientBoostingClassifier(n_estimators=100, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth':np.arange( 2,6,1 ).tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_gbtc = GridSearchCV(gbtc, parameters,cv=6, n_jobs= -1, iid = True,  refit= True,pre_dispatch= '2*n_jobs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_gbtc.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmatrix(clf_gbtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score_gbtc = clf_gbtc.fit(X_train_scaled, y_train).predict_proba(X_test_scaled)\n",
    "y_score_gbtc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_multiclass_roc(y_score_gbtc, X_test_scaled, y_test, n_classes=3, figsize=(20, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed= 24\n",
    "xgb1 = xgb.sklearn.XGBClassifier(learning_rate =0.1,n_estimators=100,max_depth=5,min_child_weight=11,\n",
    "             gamma=0.1,subsample=0.8,colsample_bytree=0.7,objective='multi:softprob',n_jobs=-1,scale_pos_weight=1,\n",
    "             seed=seed)\n",
    "    \n",
    "xgb1.fit(X_train, y_train)\n",
    "    \n",
    "y_pred= xgb1.predict(X_test)\n",
    "    \n",
    "    #confusion matrix and classification report\n",
    "    \n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
